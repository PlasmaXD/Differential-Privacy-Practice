{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ja-ginza in /home/jun/.pyenv/versions/3.11.8/lib/python3.11/site-packages (5.2.0)\n",
      "Requirement already satisfied: spacy<4.0.0,>=3.4.4 in /home/jun/.pyenv/versions/3.11.8/lib/python3.11/site-packages (from ja-ginza) (3.7.5)\n",
      "Requirement already satisfied: sudachipy<0.7.0,>=0.6.2 in /home/jun/.pyenv/versions/3.11.8/lib/python3.11/site-packages (from ja-ginza) (0.6.8)\n",
      "Requirement already satisfied: sudachidict-core>=20210802 in /home/jun/.pyenv/versions/3.11.8/lib/python3.11/site-packages (from ja-ginza) (20240409)\n",
      "Requirement already satisfied: ginza<5.3.0,>=5.2.0 in /home/jun/.pyenv/versions/3.11.8/lib/python3.11/site-packages (from ja-ginza) (5.2.0)\n",
      "Requirement already satisfied: plac>=1.3.3 in /home/jun/.pyenv/versions/3.11.8/lib/python3.11/site-packages (from ginza<5.3.0,>=5.2.0->ja-ginza) (1.4.3)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /home/jun/.pyenv/versions/3.11.8/lib/python3.11/site-packages (from spacy<4.0.0,>=3.4.4->ja-ginza) (3.0.12)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /home/jun/.pyenv/versions/3.11.8/lib/python3.11/site-packages (from spacy<4.0.0,>=3.4.4->ja-ginza) (1.0.5)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /home/jun/.pyenv/versions/3.11.8/lib/python3.11/site-packages (from spacy<4.0.0,>=3.4.4->ja-ginza) (1.0.10)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /home/jun/.pyenv/versions/3.11.8/lib/python3.11/site-packages (from spacy<4.0.0,>=3.4.4->ja-ginza) (2.0.8)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /home/jun/.pyenv/versions/3.11.8/lib/python3.11/site-packages (from spacy<4.0.0,>=3.4.4->ja-ginza) (3.0.9)\n",
      "Requirement already satisfied: thinc<8.3.0,>=8.2.2 in /home/jun/.pyenv/versions/3.11.8/lib/python3.11/site-packages (from spacy<4.0.0,>=3.4.4->ja-ginza) (8.2.4)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /home/jun/.pyenv/versions/3.11.8/lib/python3.11/site-packages (from spacy<4.0.0,>=3.4.4->ja-ginza) (1.1.3)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /home/jun/.pyenv/versions/3.11.8/lib/python3.11/site-packages (from spacy<4.0.0,>=3.4.4->ja-ginza) (2.4.8)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /home/jun/.pyenv/versions/3.11.8/lib/python3.11/site-packages (from spacy<4.0.0,>=3.4.4->ja-ginza) (2.0.10)\n",
      "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in /home/jun/.pyenv/versions/3.11.8/lib/python3.11/site-packages (from spacy<4.0.0,>=3.4.4->ja-ginza) (0.4.1)\n",
      "Requirement already satisfied: typer<1.0.0,>=0.3.0 in /home/jun/.pyenv/versions/3.11.8/lib/python3.11/site-packages (from spacy<4.0.0,>=3.4.4->ja-ginza) (0.12.3)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /home/jun/.pyenv/versions/3.11.8/lib/python3.11/site-packages (from spacy<4.0.0,>=3.4.4->ja-ginza) (4.66.2)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /home/jun/.pyenv/versions/3.11.8/lib/python3.11/site-packages (from spacy<4.0.0,>=3.4.4->ja-ginza) (2.31.0)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /home/jun/.pyenv/versions/3.11.8/lib/python3.11/site-packages (from spacy<4.0.0,>=3.4.4->ja-ginza) (2.7.0)\n",
      "Requirement already satisfied: jinja2 in /home/jun/.pyenv/versions/3.11.8/lib/python3.11/site-packages (from spacy<4.0.0,>=3.4.4->ja-ginza) (3.1.3)\n",
      "Requirement already satisfied: setuptools in /home/jun/.pyenv/versions/3.11.8/lib/python3.11/site-packages (from spacy<4.0.0,>=3.4.4->ja-ginza) (69.5.1)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/jun/.pyenv/versions/3.11.8/lib/python3.11/site-packages (from spacy<4.0.0,>=3.4.4->ja-ginza) (23.2)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /home/jun/.pyenv/versions/3.11.8/lib/python3.11/site-packages (from spacy<4.0.0,>=3.4.4->ja-ginza) (3.4.0)\n",
      "Requirement already satisfied: numpy>=1.19.0 in /home/jun/.pyenv/versions/3.11.8/lib/python3.11/site-packages (from spacy<4.0.0,>=3.4.4->ja-ginza) (1.26.4)\n",
      "Requirement already satisfied: language-data>=1.2 in /home/jun/.pyenv/versions/3.11.8/lib/python3.11/site-packages (from langcodes<4.0.0,>=3.2.0->spacy<4.0.0,>=3.4.4->ja-ginza) (1.2.0)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /home/jun/.pyenv/versions/3.11.8/lib/python3.11/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<4.0.0,>=3.4.4->ja-ginza) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.18.1 in /home/jun/.pyenv/versions/3.11.8/lib/python3.11/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<4.0.0,>=3.4.4->ja-ginza) (2.18.1)\n",
      "Requirement already satisfied: typing-extensions>=4.6.1 in /home/jun/.pyenv/versions/3.11.8/lib/python3.11/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<4.0.0,>=3.4.4->ja-ginza) (4.11.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/jun/.pyenv/versions/3.11.8/lib/python3.11/site-packages (from requests<3.0.0,>=2.13.0->spacy<4.0.0,>=3.4.4->ja-ginza) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/jun/.pyenv/versions/3.11.8/lib/python3.11/site-packages (from requests<3.0.0,>=2.13.0->spacy<4.0.0,>=3.4.4->ja-ginza) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/jun/.pyenv/versions/3.11.8/lib/python3.11/site-packages (from requests<3.0.0,>=2.13.0->spacy<4.0.0,>=3.4.4->ja-ginza) (1.26.18)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/jun/.pyenv/versions/3.11.8/lib/python3.11/site-packages (from requests<3.0.0,>=2.13.0->spacy<4.0.0,>=3.4.4->ja-ginza) (2024.2.2)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /home/jun/.pyenv/versions/3.11.8/lib/python3.11/site-packages (from thinc<8.3.0,>=8.2.2->spacy<4.0.0,>=3.4.4->ja-ginza) (0.7.11)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /home/jun/.pyenv/versions/3.11.8/lib/python3.11/site-packages (from thinc<8.3.0,>=8.2.2->spacy<4.0.0,>=3.4.4->ja-ginza) (0.1.5)\n",
      "Requirement already satisfied: click>=8.0.0 in /home/jun/.pyenv/versions/3.11.8/lib/python3.11/site-packages (from typer<1.0.0,>=0.3.0->spacy<4.0.0,>=3.4.4->ja-ginza) (8.1.7)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in /home/jun/.pyenv/versions/3.11.8/lib/python3.11/site-packages (from typer<1.0.0,>=0.3.0->spacy<4.0.0,>=3.4.4->ja-ginza) (1.5.4)\n",
      "Requirement already satisfied: rich>=10.11.0 in /home/jun/.pyenv/versions/3.11.8/lib/python3.11/site-packages (from typer<1.0.0,>=0.3.0->spacy<4.0.0,>=3.4.4->ja-ginza) (13.7.1)\n",
      "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /home/jun/.pyenv/versions/3.11.8/lib/python3.11/site-packages (from weasel<0.5.0,>=0.1.0->spacy<4.0.0,>=3.4.4->ja-ginza) (0.18.1)\n",
      "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /home/jun/.pyenv/versions/3.11.8/lib/python3.11/site-packages (from weasel<0.5.0,>=0.1.0->spacy<4.0.0,>=3.4.4->ja-ginza) (7.0.4)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/jun/.pyenv/versions/3.11.8/lib/python3.11/site-packages (from jinja2->spacy<4.0.0,>=3.4.4->ja-ginza) (2.1.5)\n",
      "Requirement already satisfied: marisa-trie>=0.7.7 in /home/jun/.pyenv/versions/3.11.8/lib/python3.11/site-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy<4.0.0,>=3.4.4->ja-ginza) (1.2.0)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /home/jun/.pyenv/versions/3.11.8/lib/python3.11/site-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<4.0.0,>=3.4.4->ja-ginza) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /home/jun/.pyenv/versions/3.11.8/lib/python3.11/site-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<4.0.0,>=3.4.4->ja-ginza) (2.17.2)\n",
      "Requirement already satisfied: wrapt in /home/jun/.pyenv/versions/3.11.8/lib/python3.11/site-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy<4.0.0,>=3.4.4->ja-ginza) (1.16.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in /home/jun/.pyenv/versions/3.11.8/lib/python3.11/site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<4.0.0,>=3.4.4->ja-ginza) (0.1.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install ja-ginza\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import spacy\n",
    "import itertools\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from typing import List, Tuple\n",
    "\n",
    "# CSVファイルの読み込み\n",
    "import pandas as pd\n",
    "import spacy\n",
    "import itertools\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from typing import List, Tuple\n",
    "\n",
    "# CSVファイルの読み込み\n",
    "data_path = './data/reviews_with_sentiment.csv'\n",
    "df = pd.read_csv(data_path)\n",
    "\n",
    "# spaCyモデルの読み込み\n",
    "nlp = spacy.load('ja_ginza')\n",
    "\n",
    "# 必要な品詞\n",
    "POS = ['ADJ', 'ADV', 'INTJ', 'PROPN', 'NOUN', 'VERB']\n",
    "MAX_TERMS_IN_DOC = 5\n",
    "NGRAM = 1\n",
    "MAX_DF = 1.0\n",
    "MIN_DF = 0.0\n",
    "NUM_VOCAB = 10000\n",
    "\n",
    "# ヘルパー関数\n",
    "def flatten(*lists) -> list:\n",
    "    return list(itertools.chain.from_iterable(lists))\n",
    "\n",
    "def remove_duplicates(l: List[Tuple[str, float]]) -> List[Tuple[str, float]]:\n",
    "    return list({e[0]: e[1] for e in l}.items())\n",
    "\n",
    "# 形態素解析の実施\n",
    "df[\"doc\"] = [nlp(review) for review in df[\"review\"]]\n",
    "\n",
    "# Bag-of-Wordsの作成\n",
    "bows = {}\n",
    "cvs = {}\n",
    "for sentiment in df[\"sentiment\"].unique():\n",
    "    tokens = []\n",
    "    for doc in df[df[\"sentiment\"] == sentiment][\"doc\"]:\n",
    "        similarities = [(token.similarity(doc), token.lemma_) for token in doc if token.pos_ in POS and token.has_vector]\n",
    "        similarities = remove_duplicates(similarities)\n",
    "        similarities = sorted(similarities, key=lambda sim: sim[0], reverse=True)[:MAX_TERMS_IN_DOC]\n",
    "        tokens.append([similarity[1] for similarity in similarities])\n",
    "    flattened_tokens = [' '.join(token_list) for token_list in tokens]\n",
    "    cv = CountVectorizer(ngram_range=(1, NGRAM), max_df=MAX_DF, min_df=MIN_DF, max_features=NUM_VOCAB)\n",
    "    bows[sentiment] = cv.fit_transform(flattened_tokens).toarray()\n",
    "    cvs[sentiment] = cv\n",
    "df = pd.read_csv(data_path)\n",
    "\n",
    "# spaCyモデルの読み込み\n",
    "nlp = spacy.load('ja_ginza')\n",
    "\n",
    "# 必要な品詞\n",
    "POS = ['ADJ', 'ADV', 'INTJ', 'PROPN', 'NOUN', 'VERB']\n",
    "MAX_TERMS_IN_DOC = 5\n",
    "NGRAM = 1\n",
    "MAX_DF = 1.0\n",
    "MIN_DF = 0.0\n",
    "NUM_VOCAB = 10000\n",
    "\n",
    "# ヘルパー関数\n",
    "def flatten(*lists) -> list:\n",
    "    return list(itertools.chain.from_iterable(lists))\n",
    "\n",
    "def remove_duplicates(l: List[Tuple[str, float]]) -> List[Tuple[str, float]]:\n",
    "    return list({e[0]: e[1] for e in l}.items())\n",
    "\n",
    "# 形態素解析の実施\n",
    "df[\"doc\"] = [nlp(review) for review in df[\"review\"]]\n",
    "\n",
    "# Bag-of-Wordsの作成\n",
    "bows = {}\n",
    "cvs = {}\n",
    "for sentiment in df[\"sentiment\"].unique():\n",
    "    tokens = []\n",
    "    for doc in df[df[\"sentiment\"] == sentiment][\"doc\"]:\n",
    "        similarities = [(token.similarity(doc), token.lemma_) for token in doc if token.pos_ in POS and token.has_vector]\n",
    "        similarities = remove_duplicates(similarities)\n",
    "        similarities = sorted(similarities, key=lambda sim: sim[0], reverse=True)[:MAX_TERMS_IN_DOC]\n",
    "        tokens.append([similarity[1] for similarity in similarities])\n",
    "    flattened_tokens = [' '.join(token_list) for token_list in tokens]\n",
    "    cv = CountVectorizer(ngram_range=(1, NGRAM), max_df=MAX_DF, min_df=MIN_DF, max_features=NUM_VOCAB)\n",
    "    bows[sentiment] = cv.fit_transform(flattened_tokens).toarray()\n",
    "    cvs[sentiment] = cv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "TOP_K = 20\n",
    "\n",
    "# 単語の登場頻度を計算\n",
    "vocabs = {}\n",
    "term_frequencies = {}\n",
    "for sentiment in df[\"sentiment\"].unique():\n",
    "    bow = bows[sentiment]\n",
    "    cv = cvs[sentiment]\n",
    "    vocab = cv.vocabulary_\n",
    "    term_frequency = np.sum(bow, axis=0)\n",
    "    vocabs[sentiment] = vocab\n",
    "    term_frequencies[sentiment] = term_frequency\n",
    "    indices_topk = np.argsort(term_frequency)[::-1][:TOP_K]\n",
    "    bow_topk = np.take(bow, indices_topk, axis=1)\n",
    "    reverse_vocab = {vocab[k]: k for k in vocab.keys()}\n",
    "    words = [reverse_vocab[i] for i in indices_topk]\n",
    "    \n",
    "    print(f\"{sentiment} :\")\n",
    "    for w, c in zip(words, term_frequency[indices_topk]):\n",
    "        print(w, \":\", c)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: python-dp in /home/jun/.pyenv/versions/3.11.8/lib/python3.11/site-packages (1.1.4)\n"
     ]
    }
   ],
   "source": [
    "!pip install python-dp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "from pydp.algorithms.laplacian import Count\n",
    "from typing import List, Tuple\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_for_private_counts(tf: np.ndarray) -> List[np.ndarray]:\n",
    "    repeated_words = []\n",
    "    for i, term in enumerate(tf):\n",
    "        repeated_words.append(np.repeat(i, term))\n",
    "    return repeated_words\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cal_private_count(\n",
    "    epsilon: float,\n",
    "    max_partition_contributed: float,\n",
    "    max_contributions_per_partition: float,\n",
    "    repeated_words: List[np.ndarray],\n",
    ") -> List[int]:\n",
    "    private_counts = []\n",
    "    for repeated_word in repeated_words:\n",
    "        counter = Count(epsilon, max_partition_contributed, max_contributions_per_partition)\n",
    "        count = counter.quick_result(repeated_word)\n",
    "        private_counts.append(count)\n",
    "    return private_counts\n",
    "\n",
    "def top_k_words_and_counts(k: int, tf: np.ndarray, vocab: dict) -> List[Tuple[str, int]]:\n",
    "    indices_topk = np.argsort(tf)[::-1][:k]\n",
    "    reverse_vocab = {vocab[key]: key for key in vocab.keys()}\n",
    "    words = [reverse_vocab[i] for i in indices_topk]\n",
    "    counts = [tf[i] for i in indices_topk]\n",
    "    return list(zip(words, counts))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epsilons = [0.01, 0.05, 0.1, 0.3, 0.7, 1.0, 2.0, 3.0, 7.0, 10.0]\n",
    "MAX_DUPLICATED_TERMS = 1\n",
    "\n",
    "for eps in epsilons:\n",
    "    print(f\"ε: {eps}\")\n",
    "    for sentiment in df[\"sentiment\"].unique():\n",
    "        repeated_words = preprocess_for_private_counts(term_frequencies[sentiment])\n",
    "        private_counts = cal_private_count(eps, MAX_TERMS_IN_DOC, MAX_DUPLICATED_TERMS, repeated_words)\n",
    "        words_and_counts = top_k_words_and_counts(TOP_K, private_counts, vocabs[sentiment])\n",
    "        print(f\"{sentiment} : {words_and_counts}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
